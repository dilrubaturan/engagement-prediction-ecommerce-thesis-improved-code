# -*- coding: utf-8 -*-
"""2_models_cv.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UKhcYpxS-YJE6Arq4XnbN2oKNASmNl3K
"""

#!/usr/bin/env python
# grid-search + cross-validation for four ML models

from pathlib import Path
import argparse, joblib, json
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from utils import to_numeric, eval_report, SEED, save_json

def split_scale(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=SEED
    )
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test  = scaler.transform(X_test)
    return X_train, X_test, y_train, y_test, scaler

def grid(model, params):
    return GridSearchCV(
        estimator=model,
        param_grid=params,
        scoring="f1_macro",
        cv=5,
        n_jobs=-1,
        verbose=0
    )

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_dir", default="data")
    args = ap.parse_args()
    d = Path(args.data_dir)

    df = pd.read_csv(d / "session_level_with_all_features.csv")
    y = df["label"]
    X = to_numeric(df.drop(columns=["label", "session_id"], errors="ignore"))

    X_tr, X_te, y_tr, y_te, scaler = split_scale(X, y)
    (d / "models").mkdir(exist_ok=True)

    models = {
        "logreg": (
            LogisticRegression(max_iter=1000, random_state=SEED),
            {"C":[0.01,0.1,1,10]}
        ),
        "rf": (
            RandomForestClassifier(random_state=SEED),
            {"n_estimators":[100,200], "max_depth":[10,20]}
        ),
        "xgb": (
            XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=SEED),
            {"learning_rate":[0.1,0.05], "max_depth":[3,5],
             "n_estimators":[100,200], "subsample":[0.8,1.0]}
        ),
        "lgbm": (
            LGBMClassifier(random_state=SEED),
            {"learning_rate":[0.1,0.05], "max_depth":[3,5],
             "n_estimators":[50,100], "subsample":[0.8,1.0]}
        ),
    }

    for name,(est,params) in models.items():
        gs = grid(est,params).fit(X_tr,y_tr)
        best = gs.best_estimator_
        metrics = eval_report(y_te, best.predict(X_te))
        joblib.dump(best, d/"models"/f"{name}.pkl")
        save_json(metrics, d/"models"/f"{name}_metrics.json")

    joblib.dump(scaler, d/"models"/"scaler.pkl")

if __name__ == "__main__":
    main()

for name, (est, params) in models.items():
    gs = grid(est, params).fit(X_tr, y_tr)
    best = gs.best_estimator_


    cv_df = pd.DataFrame(gs.cv_results_)
    cv_df.to_csv(d / "models" / f"{name}_cv_results.csv", index=False)


    metrics = eval_report(y_te, best.predict(X_te))
    joblib.dump(best, d / "models" / f"{name}.pkl")
    save_json(metrics, d / "models" / f"{name}_metrics.json")
...