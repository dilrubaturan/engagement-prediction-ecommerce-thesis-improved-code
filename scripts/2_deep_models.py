# -*- coding: utf-8 -*-
"""2_deep_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hLmbvHxweH0rRN9ePtTVOuwNPIK4jVZs
"""

#!/usr/bin/env python
# TabNet + LSTM with macro-F1 evaluation

from pathlib import Path
import argparse, joblib, json, numpy as np, pandas as pd, torch, tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from pytorch_tabnet.tab_model import TabNetClassifier
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from utils import to_numeric, eval_report, SEED, save_json

tf.random.set_seed(SEED)
torch.manual_seed(SEED)

def split_data(X, y):
    X_tr, X_te, y_tr, y_te = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=SEED
    )
    X_tr, X_val, y_tr, y_val = train_test_split(
        X_tr, y_tr, test_size=0.25, stratify=y_tr, random_state=SEED
    )
    return X_tr, X_val, X_te, y_tr, y_val, y_te

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--data_dir", default="data")
    args = ap.parse_args()
    d = Path(args.data_dir)

    df = pd.read_csv(d / "session_level_with_all_features.csv")
    y = df["label"].values
    X = to_numeric(df.drop(columns=["label", "session_id"], errors="ignore")).values
    X_tr, X_val, X_te, y_tr, y_val, y_te = split_data(X, y)

    (d / "models").mkdir(exist_ok=True)

    # ----- TabNet -----
    tabnet = TabNetClassifier(
        n_d=32, n_a=32, n_steps=5, gamma=1.5, lambda_sparse=1e-4,
        optimizer_fn=torch.optim.Adam, optimizer_params=dict(lr=2e-2),
        scheduler_params={"step_size":10,"gamma":0.9},
        scheduler_fn=torch.optim.lr_scheduler.StepLR,
        seed=SEED, verbose=0
    )
    tabnet.fit(
        X_tr, y_tr,
        eval_set=[(X_val, y_val)],
        eval_name=["val"],
        eval_metric=["f1"],
        max_epochs=200,
        patience=10,
        batch_size=1024,
        virtual_batch_size=128,
    )
    tabnet_metrics = eval_report(y_te, tabnet.predict(X_te))
    tabnet.save_model(str(d / "models" / "tabnet"))

    # ----- LSTM -----
    X_tr_lstm = X_tr.reshape((X_tr.shape[0], 1, X_tr.shape[1]))
    X_val_lstm = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))
    X_te_lstm = X_te.reshape((X_te.shape[0], 1, X_te.shape[1]))

    lstm = Sequential([
        LSTM(64, input_shape=(1, X_tr.shape[1])),
        Dropout(0.3),
        Dense(32, activation="relu"),
        Dense(1, activation="sigmoid"),
    ])
    lstm.compile(optimizer="adam", loss="binary_crossentropy")
    lstm.fit(
        X_tr_lstm, y_tr,
        validation_data=(X_val_lstm, y_val),
        epochs=30, batch_size=64,
        callbacks=[EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)],
        verbose=0
    )
    y_pred = (lstm.predict(X_te_lstm, verbose=0) > 0.5).astype(int).ravel()
    lstm_metrics = eval_report(y_te, y_pred)
    lstm.save(d / "models" / "lstm.h5")

    # ----- store metrics -----
    save_json(tabnet_metrics, d / "models" / "tabnet_metrics.json")
    save_json(lstm_metrics,  d / "models" / "lstm_metrics.json")

if __name__ == "__main__":
    main()